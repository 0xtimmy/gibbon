
% This varies by conference, sometimes 9pt:
\documentclass[preprint,10pt,nocopyrightspace]{./bibs/sigplanconf}
% The following \documentclass options may be useful:
%
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.


%% Common packages we use:

%% This is our standard package for code formatting:
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{hyperref}
\usepackage{graphicx}
% \usepackage{mathabx}
% \usepackage{mathpartir}

\usepackage[noabbrev]{cleveref}
\usepackage{enumitem}

\usepackage{wrapfig}

\newcommand{\gramdef}{\; ::= \;}
\newcommand{\gramor}{\; | \;}
\newcommand{\keywd}[1]{\; \texttt{#1} \;}
\newcommand{\keywdr}[1]{\; \texttt{#1}^{*} \;}

%----------------------------------------
%% \usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}
%% \usepackage{xargs}
%% \newcommandx{\unsure}[2][1=]{\todo[linecolor=red,backgroundcolor=red!25,bordercolor=red,#1]{#2}}
%% \newcommandx{\info}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}}
%% \newcommandx{\change}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=blue,#1]{#2}}
%% \newcommandx{\inconsistent}[2][1=]{\todo[linecolor=blue,backgroundcolor=blue!25,bordercolor=red,#1]{#2}}
%% \newcommandx{\improvement}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}
%% \newcommandx{\resolved}[2][1=]{\todo[linecolor=OliveGreen,backgroundcolor=OliveGreen!25,bordercolor=OliveGreen,#1]{#2}} % use this to mark a resolved question
%% \newcommandx{\thiswillnotshow}[2][1=]{\todo[disable,#1]{#2}} % will replace \resolved in the final document
% ----------------------------------------


% Tweak width of margin notes for this documentclass:
\setlength{\marginparwidth}{1.75cm}
% Copy this if needed to customize:
\input{./bibs/latex_templates/editingmarks}

% If we are using Haskell code in this paper:
\input{./bibs/latex_templates/haskell_style}

% Sometimes we have extra short-cuts:
% \input{macro-defs}

% Sometimes we factor large figures into commands in a separate file:
% \input{figures}

\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{CONF 'yy}{Month d--d, 20yy, City, ST, Country}
\copyrightyear{20yy}
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm}
\copyrightdoi{nnnnnnn.nnnnnnn}

% Uncomment the publication rights you want to use.
%\publicationrights{transferred}
%\publicationrights{licensed}     % this is the default
%\publicationrights{author-pays}

\titlebanner{banner above paper title}        % These are ignored unless
\preprintfooter{short description of paper}   % 'preprint' option specified.

\title{Compiling tree transformations on packed representations}
\subtitle{Faster compiler passes, parallelization ready}

\authorinfo{Name1}
           {Affiliation1}
           {Email1}
\authorinfo{Name2\and Name3}
           {Affiliation2/3}
           {Email2/3}

\maketitle

\begin{abstract}
This is the text of the abstract.
\end{abstract}

\category{CR-number}{subcategory}{third-level}

% general terms are not compulsory anymore,
% you may leave them out
\terms
term1, term2

\keywords
keyword1, keyword2

% ================================================================================
\section{Introduction}
% ================================================================================

\rn{This is an example peanut-gallery comment.}

Programs that traverse and construct trees are a niche, but an important one,
including compiler passes, HTML DOM, and particle simulations with
space-partitioning trees.
%
Yet there is almost no diversity in how modern programming languages and
compilers represent trees and their traversals, so the matter would seem to be
settled.
% In the traditional representation,
Each node of the tree is a heap object, followed by fields for child nodes or
leaf values.  This representation hasn't changed since the dawn of computing and
is shared across source languages with quite different type
sytsems---e.g. algebraic datatypes v.s. class hierarchies, statically ora
dynamically typed.  The only deviations from this consensus are found within
limited high-performance scenarios where complete trees can be laid out using
address arithmetic with no intermediate nodes \cite{hpc-trees}.

%% \begin{figure}
%% %\begin{wrapfigure}{r}{0.5\textwidth} 
%% \Red{PICTURE HERE:  possibly with wrapfig.}
\begin{verbatim}
  [N|.|.]
     /  \ 
 [L 1]  [N|.|.]
          /   \
       [L 2] [L 3]
\end{verbatim}
%%   \caption{Traditional, pointer-based tree layout.}
%% \end{figure}
%\end{wrapfigure}

But perhaps the consensus was premature?  In numerical computing it's an axiom
that you cannot treat the numbers in a matrix as individual heap objects.
Rather, the emphasis is on bulk efficiency.  Likewise, many tree traversals
process trees in bulk, reading or writing them in one pass.  On such workloads,
traditional tree representations are not favored by current trends in computer
architecture.  Pointer chasing implies randomized memory access patterns.  Also,
much memory is wasted both in pointers themselves and in tags on nodes
(e.g. distinguishing ``interior'' vs ``leaf'' objects).  For example, a C
compiler uses 96 bytes
%
\rn{Double check that for alignment the C compiler is sacrificing a word for the
one byte tag field.}
%
of memory to represent the tree above.  On the other
hand, if we were sending the tree over the network, we would naturally use a
more compact format in serializing it:

% \begin{figure}
\begin{verbatim}
  [N L 1  N L 2  L 3 ]
\end{verbatim}
% \end{figure}

Here we use the same 24 bytes for the leaf numbers, but only 5 bytes for the
spine, rather than 72.  Further, a tree traversal processing this memory
representation follows a precisely linear memory access pattern, because the
data is already laid out in a preorder traversal.
Indeed, if we can compile programs to operate directly on this serialization, we
follow a precedent of using serialization formats jointly as in memory formats.
Cap'N Proto \cite{capnproto} makes it ergonomic for C++ code to operate directly
on the Protobuf serialization format in memory.  Likewise ``data baking''
\cite{data-baking} is an established practice in video games---caching assets on
disk in a format that allows them to be \il{mmap}'d into memory and used
without further conversion.  As a general example of this capability, the
Glasgow Haskell Compiler (GHC) recently added the capability to store any closed
subgraph of the heap as a {\em Compact Normal Form} (CNF) \cite{cnf-icfp15}---a
contiguous memory region that is treated as a kind of ``super object'', never
traced by the GC and collected only when there are no pointers into any of the
sub-parts of the CNF.

The packed tree format above is precisely a dense encoding of a CNF---a
transitive closure of heap objects with no escaping pointers, in this case, no
pointers {\em at all}.  But unlike GHC's CNF support, which uses regular heap
objects, colocated together, the dense tree format requires a complete
rearrangement of the compiled code that operates on the data.

% Shall we acronymize it?
% DTF - dense tree form, or dense tree format
% PTF - packed tree form
% DTP - dense tree packing

In this paper, we take a first step towards compiler support for transparently
packing a tree datatypes without changing the source program.  We make the
following contributions:

\newcommand{\calculus}{$\lambda^D_T$} % uh, Dense Tree?

\begin{itemize}
\item We use a small core language, \calculus{}, to formalize a transformation
  on programs with threes that creates an output program that operates only on
  pointers in the serialized representation.  This involves a small program
  synthesis step, and we show how the program synthesis and the selection of
  data structure shape go benefit from co-optimization.
  
\item We demonstrate that a prototype language implementation based on this
  transformation can compile a range of tree transforms to be several times
  faster than existing techniques~\cref{sec:eval-compiler}.
  
\item We show that the principle of packed-tree traversals works across a
  variety of language implementations, by benchmarking handwritten packed-tree
  programs~\cref{sec:eval-shootout}.
  
\item We show that not only do tree traversals become faster, but that their
  {\em potential parallel speedup}, increases as well \cref{sec:eval-parallel}.
\end{itemize}


% ================================================================================
\section{Motivating Example}
% Background?
% ================================================================================

\note{We use these bullets for outlining / psuedo-text.  They're removed when
  converted to actual prose.}

% ================================================================================
\section{Formal language}
% ================================================================================

\note{The calculus, plus the core lowering transforms in figures.}

We present two languages: L1, a simple purely functional, first-order programming
language with sum and product types; and L2, an imperative programming language
with mutable arrays and pointer arithmetic, as well as a type-and-effect system.

\subsection{L1: Source language}

\note{Do we have a problem if we just stick to the way sums and products are usually presented?
  Or do we need recursive types? Also, binary sums and products might make the switch form
  in L2 less interesting.}

\begin{figure}
  \begin{displaymath}
    \keywd{v} \in \; Var, \:
    \keywd{n} \in \; Int, \: \keywd{p} \in \; Prim, \: \keywd{c} \in \; Tag
  \end{displaymath}
  \begin{displaymath}
    \begin{aligned}
      \keywd{prog} \gramdef & \keywdr{decl} \keywd{e} \\
      \keywd{decl} \gramdef & \keywd{v} \mapsto \lambda \keywd{v:t}. \keywd{e} \\
      \keywd{t} \gramdef & \keywd{int} \gramor \keywd{t} \rightarrow \keywd{t} \gramor \keywd{t} * \keywd{t}  \\
      \gramor & \keywd{t} + \keywd{t} \\
      \keywd{e} \gramdef & \keywd{v} \gramor \keywd{n} \gramor \keywd{e} \keywd{p} \keywd{e} \gramor \keywd{e} \keywd{e} \\
      \gramor & \keywd{(e,e)} \gramor \# 1 \keywd{e} \gramor \# 2 \keywd{e} \\
      \gramor & \keywd{let} \keywd{(v,t,e)} \keywd{e} \\
      \gramor & \keywd{case} \keywd{e} \keywd{of} \keywd{(e,e)} \\
      \gramor & \keywd{inl} \keywd{t} \keywd{e} \gramor \keywd{inr} \keywd{t} \keywd{e} \\
    \end{aligned}
  \end{displaymath}
  \caption{Grammar for source language}
\end{figure}

\subsection{L2: Target language}

\begin{figure}
\begin{displaymath}
  \begin{aligned}
    \keywd{x} \gramdef & \keywd{n} \gramor \keywd{v} \\
    \keywd{t} \gramdef & \keywd{int} \gramor \keywd{cursor} \gramor \keywd{t} \rightarrow \keywd{t} \gramor \keywd{t} * \keywd{t} \\
    \keywd{e} \gramdef & \keywd{x} \gramor \keywd{x} \keywd{p} \keywd{x} \gramor \keywd{v} \keywd{x} \\
    \gramor & \keywd{(x,x)} \gramor \# 1 \keywd{x} \gramor \# 2 \keywd{x} \\
    \gramor & \keywd{let} \keywd{(v,t,e)} \keywd{e} \\
    \gramor & \keywd{ifeq} \keywd{(x,x)} \keywd{e} \keywd{e} \\
    \gramor & \keywd{switch} \keywd{x} \keywdr{(n,v,e)} \\
    \gramor & \keywd{newbuff} \keywd{n} \\
    \gramor & \keywd{writetag} \keywd{v} \keywd{n} \\
    \gramor & \keywd{writeint} \keywd{v} \keywd{x} \\
    \gramor & \keywd{readtag} \keywd{v} \\
    \gramor & \keywd{readint} \keywd{v} 
  \end{aligned}
\end{displaymath}
\caption{Grammar for target language}
\end{figure}

% ================================================================================
\section{Implementation}
% ================================================================================



% ================================================================================
\section{Evaluation}
% ================================================================================



\subsection{Additional tree benchmarks}
% ----------------------------------------

\note{Non-compiler benchmark(s)}


% ================================================================================
\section{Future work}
% ================================================================================

\note{Data type factoring, storing leaves in a separate, dense, aligned vector.
This enables (1) vectorization of numeric operations, and (2) separating
out pointers that the GC must traverse.  This can prove essential for an
open-world implementation in a managed language.}



% ================================================================================
\appendix
\section{Appendix Title}
% ================================================================================

This is the text of the appendix, if you need one.

\acks

Acknowledgments, if needed.

% \bibliographystyle{abbrvnat}
\bibliographystyle{abbrv}

% If you can't commit to the submodule right this second, just copy
% this file to ./refs.bib :
\bibliography{bibs/refs}

% The bibliography should be embedded for final submission.
%% \begin{thebibliography}{}
%% \softraggedright
%% \bibitem[Smith et~al.(2009)Smith, Jones]{smith02}
%% P. Q. Smith, and X. Y. Jones. ...reference text...
%% \end{thebibliography}


\end{document}


